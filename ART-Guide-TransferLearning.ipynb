{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabcffb-73db-46a2-bc3d-fb0e79b50bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import flatbuffers\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip\n",
    "from tensorflow.keras.layers import RandomRotation\n",
    "from tensorflow.keras.layers import RandomZoom\n",
    "from tensorflow.keras.layers import RandomTranslation\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support import metadata as _metadata\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80bdb5-1f3d-4589-9f5c-cf48b12151bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(directory=\"./train\", image_size=(224, 224))\n",
    "val_dataset = image_dataset_from_directory(directory=\"./val\", image_size=(224, 224))\n",
    "test_dataset = image_dataset_from_directory(directory=\"./test\", image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72beb83b-622e-4228-835d-3f39675c5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb9713-9c84-44b4-9a92-769326e42237",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d51c1-8c39-45cd-8d6f-80135bfadb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet50(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93549c15-e0ee-4c8a-b74e-d6b1ab8fbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = resnet50_base(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(5, activation=\"softmax\")(x)\n",
    "transfer_model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d027e-063e-4435-9105-3e96ee3fdd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea52d2c-68a6-406b-8bee-c6ec1b85ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddfc464-f582-47a6-81e4-26899deb84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model_history = transfer_model.fit(train_dataset, epochs=15,\n",
    "                validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd04beb-1239-4598-bb18-fa9ed3a994e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transfer_model_history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a843ba-2296-45dc-a18e-42cb2817c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet50_base.layers:\n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080e1dd-fc35-4caf-bcfd-9e95bde2fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=RMSprop(learning_rate=0.001), \n",
    "                       loss=\"sparse_categorical_crossentropy\", \n",
    "                       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36c7d6-a451-4030-a88c-3cb0343ee5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model_history = transfer_model.fit(train_dataset, epochs=30,\n",
    "                validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c02be-90e8-441a-9860-458889f19a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transfer_model_history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646512a-d742-4926-8329-93bcaad54b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './horseTest.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    path, target_size=(224, 224)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = transfer_model.predict(img_array)\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {} percent confidence.\"\n",
    "    .format(class_names[np.argmax(predictions[0])], 100 * np.max(predictions[0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcb86c-c0ec-40ec-a58b-60c190f7c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './mocopsisTest.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    path, target_size=(224, 224)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = transfer_model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b148497-c957-4f4a-895e-2875f326ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './test4.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    path, target_size=(224, 224)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = transfer_model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b2319-63a0-4932-812d-1f51ba664c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The convnet that was trained and tuned using transfer learning\n",
    "test_loss, test_acc = transfer_model.evaluate(test_dataset)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1dd538-3b81-41b9-91b3-ff14b71030d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(transfer_model)\n",
    "\n",
    "# quantization, set the optimization mode and data type\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "model_file = 'transfer_model.tflite'\n",
    "with open(model_file, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
