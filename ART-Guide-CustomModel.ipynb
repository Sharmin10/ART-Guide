{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabcffb-73db-46a2-bc3d-fb0e79b50bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import flatbuffers\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip\n",
    "from tensorflow.keras.layers import RandomRotation\n",
    "from tensorflow.keras.layers import RandomZoom\n",
    "from tensorflow.keras.layers import RandomTranslation\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support import metadata as _metadata\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80bdb5-1f3d-4589-9f5c-cf48b12151bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(directory=\"./train\", image_size=(224, 224))\n",
    "val_dataset = image_dataset_from_directory(directory=\"./val\", image_size=(224, 224))\n",
    "test_dataset = image_dataset_from_directory(directory=\"./test\", image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72beb83b-622e-4228-835d-3f39675c5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd792f9d-343a-4d8f-b757-e0cf7dd8e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_path = 'labels.txt'\n",
    "with open(label_file_path, 'w') as f:\n",
    "    f.write('\\n'.join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e590d72-3602-4b81-88c0-38dc75eeaae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_layers = Sequential([\n",
    "   Input(shape=(224, 224, 3)),\n",
    "   RandomFlip(mode=\"horizontal\"),\n",
    "   RandomRotation(factor=0.1),\n",
    "   RandomZoom(height_factor=(-0.2, 0.2)),\n",
    "   RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1232815-016f-452d-88c4-9246f95b7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = augmentation_layers(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b815c-a6f2-4735-a01c-9488cf00d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc1b7f-b3ab-44dd-90b7-d1cbde0bb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = RandomFlip(mode=\"horizontal\")(inputs)\n",
    "x = RandomRotation(factor=0.1)(x)\n",
    "x = RandomZoom(height_factor=(-0.2, 0.2))(x)\n",
    "x = RandomTranslation(height_factor=0.2, width_factor=0.2)(x)\n",
    "\n",
    "x = Rescaling(scale=1./255)(x)\n",
    "\n",
    "x = Normalization()(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec02c0-7059-46d1-928d-c907d56d5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0cb75-45d3-43e1-a4c0-5c5b78e187f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da1b372-4ec6-4029-a3a3-e7c642c59189",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=60,\n",
    "                validation_data=val_dataset,\n",
    "                callbacks=[EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)],\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ab02c-18db-4055-b147-8c04311acc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646512a-d742-4926-8329-93bcaad54b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './horsetest.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    path, target_size=(224, 224)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {} percent confidence.\"\n",
    "    .format(class_names[np.argmax(predictions[0])], 100 * np.max(predictions[0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcb86c-c0ec-40ec-a58b-60c190f7c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './closeofdaytest.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    path, target_size=(224, 224)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf9731-f99e-487c-a328-3cc7246be119",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554b8b8-7461-4bb7-a5e4-3fd920e3c417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# quantization, set the optimization mode and data type\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "model_file = 'artmodel.tflite'\n",
    "with open(model_file, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a0c25-afc2-42ea-a8e4-4008d23171e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"ART-Guide\"\n",
    "model_meta.description = (\"Identify the most prominent object in the \"\n",
    "                          \"image from a set of %d categories.\" %\n",
    "                          num_classes)\n",
    "model_meta.version = \"v1\"\n",
    "model_meta.author = \"Sharmin_Akter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa846bc7-b310-407c-8362-3da0a4434411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates input info.\n",
    "input_meta = _metadata_fb.TensorMetadataT()\n",
    "input_meta.name = \"image\"\n",
    "input_meta.description = (\n",
    "    \"Input image to be classified. The expected image is {0} x {1}, with \"\n",
    "    \"three channels (red, blue, and green) per pixel. Each value in the \"\n",
    "    \"tensor is a single byte between 0 and 255.\".format(224, 224))\n",
    "input_meta.content = _metadata_fb.ContentT()\n",
    "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "input_meta.content.contentProperties.colorSpace = (\n",
    "    _metadata_fb.ColorSpaceType.RGB)\n",
    "input_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.ImageProperties)\n",
    "input_normalization = _metadata_fb.ProcessUnitT()\n",
    "input_normalization.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
    "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "input_normalization.options.mean = [0.0]\n",
    "input_normalization.options.std = [1.0]\n",
    "input_meta.processUnits = [input_normalization]\n",
    "input_stats = _metadata_fb.StatsT()\n",
    "input_stats.max = [255]\n",
    "input_stats.min = [0]\n",
    "input_meta.stats = input_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd261e7-b36f-465a-a16d-e4fc2712043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_meta = _metadata_fb.TensorMetadataT()\n",
    "output_meta.name = \"probability\"\n",
    "output_meta.description = \"Probabilities of the {} labels respectively.\".format(num_classes)\n",
    "output_meta.content = _metadata_fb.ContentT()\n",
    "output_meta.content.content_properties = _metadata_fb.FeaturePropertiesT()\n",
    "output_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_stats = _metadata_fb.StatsT()\n",
    "output_stats.max = [1.0]\n",
    "output_stats.min = [0.0]\n",
    "output_meta.stats = output_stats\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = os.path.basename(label_file_path)\n",
    "label_file.description = \"Labels for objects that the model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_AXIS_LABELS\n",
    "output_meta.associatedFiles = [label_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb0495-4ad1-43d4-9040-c05b5d77ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "subgraph.inputTensorMetadata = [input_meta]\n",
    "subgraph.outputTensorMetadata = [output_meta]\n",
    "model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a97eb1-5cbc-43c7-8fd0-c2cfe46e7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies model_file to export_path\n",
    "export_model_path = \"ArtGuideModel_with_metadata.tflite\"\n",
    "tf.io.gfile.copy(model_file, export_model_path, overwrite=True)\n",
    "\n",
    "# populates metadata\n",
    "populator = _metadata.MetadataPopulator.with_model_file(export_model_path)\n",
    "populator.load_metadata_buffer(metadata_buf)\n",
    "populator.load_associated_files([label_file_path])\n",
    "populator.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5013041-9325-42e3-a91f-48d8594d5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=export_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6a7d1-9fe9-4281-8ad4-2752b7d96325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n--------Input Details of Model-------------------n\")\n",
    "input_details = interpreter.get_input_details()\n",
    "print(input_details)\n",
    "\n",
    "print(\"\\nn--------Output Details of Model-------------------n\")\n",
    "output_details = interpreter.get_output_details()\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6149621-9312-4f05-841f-fe7423fb8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2def2d-ac78-41c4-b245-1f68c058c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972716d-f14e-41de-8bdd-0a6c0b7dca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c9782-3ceb-46f6-a07e-b326fe033a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "score_lite = tf.nn.softmax(predictions)\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score_lite)], 100 * np.max(score_lite))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
